pig -help

pig

grunt>
load_data = load '/user/cloudera/demo.txt';
dump load_data

help

--to execute a pig script in pig
pig -file /root/script_file.pig //to execute outside grunt

grunt>
exec /root/script_file.pig

--------------------------------------

grunt>
lines = load '/root/file.txt' using PigStorage() as (line:chararray); //lines -> bag, line -> column name, chararray -> datatype
describe lines;

explain lines; // to see explain plan how the data will be read

--to tokenize each word
words = FOREACH lines GENERATE FLATTEN(TOKENIZE(line)) as word;
describe words
explain words

grouped = GROUP words BY word;
describe grouped;

wordcount = FOREACH grouped GENERATE group, COUNT(words);
dump wordcount;

---------------------------------------------------------------------------------
--to execute from .pig script file (save below lines as a .pig file

lines = load '/root/file.txt' using PigStorage() as (line:chararray);
words = FOREACH lines GENERATE FLATTEN(TOKENIZE(line)) as word;
grouped = GROUP words BY word;
wordcount = FOREACH grouped GENERATE group, COUNT(words);
dump wordcount;

---------------------------------------------------------------------------------
-- now execute from pig 
grunt>
exec file.pig;

---------------------------------------------

--to practice import retail_db from mysql into hdfs dir using sqoop import-all-tables
sqoop import-all-tables \
 --connect "jdbc:mysql://quickstart.cloudera:3306/retail_db" \
 --username retail_dba \
 --password cloudera \
 --warehouse-dir /user/cloudera/retail_db \
 -m 12

--to access hdfs file system inside pig grunt
grunt>
fs -ls /user/cloudera/retail_db
fs -cat /user/cloudera/retail_db/departments/*  //check the delimiters

--read data without defining schema
grunt>
departments = load /user/cloudera/retail_db/departments using PigStorage(',');  

Note: *dir is enough no need of file name unless if you limit the access to exact file

describe departments; //data without schema

--lets read
department_id = foreach departments generate $0; //$0 -> first column in the bag or relation
describe department_id; //by default the it will take the file in bytearray data type

--to cast the type
department_id = foreach departments generate (int) $0;
describe department_id;

----------------------------------------------


--load data with schema
grunt>
departments = load '/user/cloudrea/pig_retail_db/departments' using PigStorage(',') as (department_id: int, department_name:chararray);
describe departments;

department_id = foreach departments generate department_id;  //no need to type cast in import with schema
describe department_id;

--------------------------------------------------

pig -useHCatalog //it will launch pig with hcatelog which facilitate to connect to hive
grunt> 
cards = load 'cards.deck_of_cards' using  org.apache.hive.hcatalog.pig.HCatLoader(); //it will connect to hive meta-store
//no need to mention schema / data types, it will automatically takes take data type from hive meta-store schema

dump cards;

pip = foreach cards generate pip;
pip_limit = limit pip 10;
dump pip;

-----------------------------------------------------------

 grunt> 
 --to access hdfs inside pig 
 fs -ls /;
 
 deck_of_cards = load 'hdfs://quickstart.cloudera:8020/user/hive/warehouse/cards.db/deck_of_cards' 
 using PigStorage('|') as (color: chararray, suit:chararray, pip: int); //if we are not mentioning data types the schema will be unknown in pig
 
 describe deck_of_cards;
 
 --to fetch schema from hive automatically
 deck_of_cards_hive = load 'cards.deck_of_cards' using org.apache.hive.hcatalog.pig.HCatLoader(); //if pig and hive on same cluster no need to give the obsolete path
 
 describe deck_of_cards_hive;
 
------------------------------------------------------

--to count the records--
grunt>

 deck_of_cards = load 'hdfs://quickstart.cloudera:8020/user/hive/warehouse/cards.db/deck_of_cards' 
 using PigStorage('|') as (color: chararray, suit:chararray, pip: int);

or

 deck_of_cards_hive = load 'cards.deck_of_cards' using org.apache.hive.hcatalog.pig.HCatLoader();
 
 --to filter out the column headers
 deck_of_cards_noheader = FILTER deck_of_cards_hive by pip != PIP;
 
 dump deck_of_cards_noheader;
 
 deck_of_cards_group_all = GROUP deck_of_cards_noheader ALL;
 
 deck_of_cards_count = FOREACH deck_of_cards_group_all GENERATE COUNT_STAR(deck_of_cards_noheader) AS cnt;
 
 dump deck_of_cards_count;
 
--to eliminate teh nulls
deck_of_cards_null = filter deck_of_cards by pip != '';

--to count 
deck_of_cards_null_grp = group deck_of_cards_null all;
deck_of_cards_null_count = foreach deck_of_cards_null_grp generate COUNT_STAR(deck_of_cards_null_grp) AS cnt;

dump deck_of_cards_null_count;

explain deck_of_cards_null_count;

----------------------------------------

--select distinct order_staus from orders;
--here we are going to count no of orders by order_staus in pig

pig -useHcatalog

grunt>
orders = load 'retail_db.order' using org.apache.hive.hcatalog.pig.HCatLoader();
describe orders;

--groupby order_staus
groupbystatus = group orders by order_status;
describe groupbystatus;
groupbystatuslimit = limit groupbystatus 10;
dump groupbystatuslimit;

countbyorderstatus = FOREACH groupbystatus GENERATE group, COUNT(orders) as cnt;	//to count we can use bag name (orders) or any column name
dump countbyorderstatus

------------------------------------------


hive>
create database pig_demo;
use pig_demo
create table departments (department_id int, department_name string);
create table categories (category_id int, category_department_id int, category_name string);
create table customers (customer_id int, customer_fname string, customer_lname string, customer_email string, customer_password string,
 customer_street string, customer_city string, customer_state string, customer_zipcode string);
create table order_items (order_item_id int, order_item_order_id int, order_item_product_id int, order_item_quantity tinyint,
 order_item_subtotal double, order_item_product_price double);
create table orders (order_id int, order_date string, order_customer_id int, order_status string);
create table products (product_id int, product_category_id int, product_name string, product_description string, product_price double, product_image string)
 
pig -useHCatalog
grunt>
--loading data from hdfs into pig relation
departments = LOAD '/user/cloudera/pig_retail_db/departments' USING PigStorage(',') AS (department_id: int, department_name: chararray);	//hdfs directory
--storing data from pig relation into hive table 
STORE departments INTO 'pig_demo.departments' USING org.apache.hive.hcatalog.pig.HCatStorer();	//pig_demo.departments is a database table in hive

categories = LOAD '/user/cloudera/pig_retail_db/categories' USING PigStorage(',') AS (category_id: int, category_department_id: int, category_name: chararray); 
--schema is very important it should match with hive table and pig relation but column names are not
STORE categories INTO 'pig_demo.categories' USING org.apache.hive.hcatalog.pig.HCatStorer();

customers = LOAD '/user/cloudera/pig_retail_db/customers' USING PigStorage (',') AS (customer_id: int, customer_fname: chararray, customer_lname: chararray, 
 customer_email: chararray, customer_password: chararray, customer_street: chararray, customer_city: chararray, customer_state: chararray, customer_zipcode: chararray);
STORE customers INTO 'pig_demo.customers' USING org.apache.hive.hcatalog.pig.HCatStorer();

order_items = LOAD  '/user/cloudera/pig_retail_db/order_items' USING PigStorage (',') AS (order_item_id: int, order_item_order_id: int,
 order_item_product_id: int, order_item_quantity: int, order_item_subtotal: double, order_item_product_price: double);					//here we casting order_item_quantity datatype tinyint into int
STORE order_items INTO 'pig_demo.order_items' USING org.apache.hive.hcatalog.pig.HCatStorer();

orders = LOAD '/user/cloudera/pig_retail_db/orders' USING PigStorage(',') AS (order_id: int, order_date: chararray, order_customer_id: int, order_status: chararray);
STORE orders INTO 'pig_demo.orders' USING org.apache.hive.hcatalog.pig.HCatStorer();

products = LOAD '/user/cloudera/pig_retail_db/products' USING PigStorage(',') AS (product_id: int, product_category_id: int, product_name: chararray,
 product_description: chararray, product_price: double, product_image: chararray);
STORE products INTO 'pig_demo.products' USING org.apache.hive.hcatalog.pig.HCatStorer();

fs -cat /user/hive/warehouse/pig_demo.db/departments/*;

output:
3Footwear	//the field between id and name is not allowed in pig console so it is showing up without space
6Outdoors	//but if we check the same in hive it will have space between them 
7Fan Shop
2Fitness
4Apparel
5Golf

-----------------------------------------------

from 12 pending


